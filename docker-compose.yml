version: '3.1'

services:
  caisse:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8086:8086"
    depends_on:
      - redis-server
      - db
      - Elasticsearch
    networks:
      - backend
      - elk  
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://db:3306/uuidstring?useSSL=false&serverTimezone=UTC&useLegacyDatetimeCode=false
      SPRING_DATASOURCE_USERNAME: root
      SPRING_DATASOURCE_PASSWORD: root
      SPRING_REDIS_HOST: redis
      SPRING_ELASTICSEARCH_CLUSTER_NODES: elasticsearch
      SPRING_KEYCLOAK_AUTH: http://51.195.11.201:8090/auth
      SPRING_KEYCLOAK_SECRET: 33a80056-95fb-4857-84b7-91c16fe2f9c5
      # SPRING_ELASTICSEARCH_CLUSTER_NODES: http://elasticsearch:9200


  redis-server:
    image: redis:latest
    restart: always
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - backend
  Elasticsearch:
    image: elasticsearch:7.16.2
    container_name: elasticsearch
    restart: always
    volumes:
      - elastic_data:/usr/share/elasticsearch/data/
    environment:
      - bootstrap.memory_lock=true
      - node.name=elasticsearch
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
    ulimits:
      memlock:
        soft: -1
        hard: -1 
    ports:
      - '9200:9200'
      - '9300:9300'
    networks:
      - elk
  filebeat:
    # image: docker.elastic.co/beats/filebeat:8.0.1
    # build: filebeat
    build:
      context: .
      dockerfile: ./Dockerfile.filebeat
    container_name: filebeat
    hostname: mydockerhost
    restart: unless-stopped
    labels:
      co.elastic.logs/enabled: "false"
    networks:
      - elk
    volumes:
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
      - type: bind
        source: /var/lib/docker
        target: /var/lib/docker
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
  Logstash:
    image: logstash:7.16.2
    container_name: logstash
    restart: always
    volumes:
      - ./logstash/:/logstash_dir
      - ./metadata/:/usr/share/logstash/metadata
      - C:\Users\HP\Desktop\mtcBackend\mysql-connector-j-8.3.0.jar:/usr/share/logstash/mysql-connector-j-8.3.0.jar
    command: logstash -f /logstash_dir/logstash.conf --config.reload.automatic
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
      - "4560:4560"
    depends_on:
      - Elasticsearch
      - db
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"    
    networks:
      - elk
      - backend
  Kibana:
    image: kibana:7.16.2
    container_name: kibana
    restart: always       
    ports:
    - '5601:5601'
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200  
    depends_on:
      - Elasticsearch  
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    networks:
      - elk

  db:
    image: mysql:5.7
    command: --max_allowed_packet=32505856
    container_name: mysql
    restart: on-failure
    ports:
      - "3308:3306"
    volumes:
      - "./db:/var/lib/mysql"
    environment:
      MYSQL_ROOT_PASSWORD: root
    networks:
      - backend
  
volumes:
  elastic_data: {}

networks:
  elk:
    driver: bridge
  backend:
    driver: bridge

